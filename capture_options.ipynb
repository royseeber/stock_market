{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform a stock option input file into a bigquery dataset\n",
    "- Calcualte equilibrium stock price where call and put implied volatility are equal\n",
    "- Isolate strikes that have a bid and are within +- 2 standard deviations of equilibrium price\n",
    "- Calculate moneyness for all strikes filtered above\n",
    "- Calculate implied volatility of all strikes filtered above\n",
    "- generate json formatted output\n",
    "- write daily output files to bigquery\n",
    "\n",
    "<b>Data Source:</b> https:\\\\historicaloptiondata.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination Table Field Definitions\n",
    "- quote_date - market closing date for which the data was captured\n",
    "- expiry_date - date on which the options expiry\n",
    "- days_to_expiry _ calendar days between quote_date and expiry_date not including the quote_date\n",
    "- underlying_price - the price of the underlying asset\n",
    "- atm_price - adjusted underlying price such that the implied volatility of calls an puts are the same\n",
    "- atm_iv - the implied volatility for both calls and puts using the atm_price as the current price\n",
    "- strike_prices\n",
    " - strike_price - price at which an option can be excercised\n",
    " - call_bid - bid price for the call option \n",
    " - call_ask - ask price for the call option\n",
    " - call_volume -  number of call contracts traded\n",
    " - call_open_iterest - number of open call contracts\n",
    " - call_moneyness - probability that the call option will close in the money on the expiry date (based on atm_implied_volatility)\n",
    " - call_iv - the implied volatiity of the call option using the midpoint between the call bid and call ask price\n",
    " - put_bid - bid price for the put option \n",
    " - put_ask - ask price for the put option\n",
    " - put_volume -  number of put contracts traded\n",
    " - put_open_iterest - number of open put contracts\n",
    " - put_moneyness - probability that the put option will close in the money on the expiry date (base on atm_implied_volatiity)\n",
    " - put_iv - the implied volatiity of the put option using the midpoint between the put bid and put ask price\n",
    "- sampling_key - a random number between 0 and 1. Facilitates repeatable data sampling without the need for a hash key \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare dependencies and constants\n",
    "from google.cloud import storage as gcs\n",
    "from google.cloud import bigquery as bq\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import datetime\n",
    "import math\n",
    "import mibian\n",
    "import scipy\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "\n",
    "STOCK_SYMBOLS = ['SPY']\n",
    "PROJECT_ID = 'expiry-week'\n",
    "DATASET_ID = 'option_quotes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interest_rate(quote_date):\n",
    "    \"return the fed funds rate that was in effect on the supplied quote date\"\n",
    "    df_fedfunds = pd.read_csv('gs://expiry-week-data/options/FEDFUNDS.csv', parse_dates=['DATE'])\n",
    "    df_fedfunds = df_fedfunds[df_fedfunds['DATE'].dt.date <= quote_date]\n",
    "    target_index = df_fedfunds['DATE'].idxmax()\n",
    "    return df_fedfunds.loc[target_index]['FEDFUNDS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_call_iv(stock_price, strike_price, interest_rate, days_to_expiry, call_price):\n",
    "    \"\"\"\n",
    "    calculate the implied volatility of a call option\n",
    "    - return annualized implied volatility as a decimal value\n",
    "    \"\"\"\n",
    "    bs = mibian.BS([stock_price, strike_price, interest_rate, days_to_expiry], callPrice=call_price)\n",
    "    return bs.impliedVolatility / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_put_iv(stock_price, strike_price, interest_rate, days_to_expiry, put_price):\n",
    "    \"\"\"\n",
    "    calculate the implied volatility of a put option\n",
    "    - return annualized implied volatility as a decimal value\n",
    "    \"\"\"\n",
    "    bs = mibian.BS([stock_price, strike_price, interest_rate, days_to_expiry], putPrice=put_price)\n",
    "    return bs.impliedVolatility / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_underlying_price(stock_price, strike_price, interest_rate, days_to_expiry, call_price, put_price):\n",
    "    \"\"\"\n",
    "    calculate equilibrium implied volatility and the adjusted underlying price at which it is acheived\n",
    "    this is the underlying price at which both call and put implied volatility are equal\n",
    "    note: interest_rate needs be passed as a percent (e.g 5 = 5%)\n",
    "    \"\"\"\n",
    "    #get starting call and put implied volatility adjusted for time to expiry\n",
    "    call_iv = calc_call_iv(stock_price, strike_price, interest_rate, days_to_expiry, call_price)       \n",
    "    put_iv = calc_put_iv(stock_price, strike_price, interest_rate, days_to_expiry, put_price)\n",
    "    \n",
    "    #calculate implied volatility difference adjusted for time to expiry\n",
    "    iv_diff = abs(put_iv - call_iv) * math.sqrt(days_to_expiry / 365) \n",
    "\n",
    "    adj_lower = stock_price  * math.exp(-iv_diff) \n",
    "    adj_upper = stock_price  * math.exp(iv_diff)\n",
    "    if put_iv > call_iv:\n",
    "        #stock price is above equilibrium price\n",
    "        adj_stock_price = (stock_price + adj_lower) / 2\n",
    "    else:\n",
    "        #stock price is below equilibrium price\n",
    "        adj_stock_price = (stock_price + adj_upper) / 2\n",
    "\n",
    "    adj_stock_price = stock_price \n",
    "    for i in range(100):\n",
    "        call_iv = calc_call_iv(adj_stock_price, strike_price, interest_rate, days_to_expiry, call_price)\n",
    "        put_iv = calc_put_iv(adj_stock_price, strike_price, interest_rate, days_to_expiry, put_price)\n",
    "        iv_diff = abs(put_iv - call_iv)\n",
    "      \n",
    "        #at point of convergence call and put iv will be the same, so return either 1\n",
    "        if iv_diff <= .001:\n",
    "            return adj_stock_price, call_iv \n",
    "        \n",
    "        if put_iv > call_iv:\n",
    "            #adjusted stock price is to high\n",
    "            adj_upper = adj_stock_price\n",
    "        else:\n",
    "            #adjusted stock price is to low\n",
    "            adj_lower = adj_stock_price\n",
    "       \n",
    "        adj_stock_price = (adj_lower + adj_upper) / 2\n",
    "\n",
    "    #throw error if convergence was not achieved\n",
    "    print('strike_price:', strike_price,'days_to_expiry:', days_to_expiry)\n",
    "    raise Exception(\"Put and Call implied volatilities did not converge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_options(df_expiry):\n",
    "    \"\"\"\n",
    "    merge calls and puts for a given expiry date and quote date using strike price as the key\n",
    "    - this will produce a straddle layout and keep only strike prices that exist on both the call and put side\n",
    "    \"\"\"\n",
    "\n",
    "    df_calls = df_expiry[df_expiry['option_type'] == 'call'].reset_index(drop=True)\n",
    "    df_calls.rename(columns={'bid': 'call_bid', 'ask': 'call_ask', 'volume': 'call_volume', 'open_interest' : 'call_open_interest'}, inplace=True)\n",
    "    del df_calls['option_type']\n",
    "\n",
    "    df_puts = df_expiry[df_expiry['option_type'] == 'put'][['bid', 'ask', 'volume', 'open_interest', 'strike_price']].reset_index(drop=True)\n",
    "    df_puts.rename(columns={'bid': 'put_bid', 'ask': 'put_ask', 'volume': 'put_volume', 'open_interest' : 'put_open_interest'}, inplace=True)\n",
    "\n",
    "    df_straddle = pd.merge(df_calls, df_puts, on='strike_price', how='inner')\n",
    "    return df_straddle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_record(quote_date, expiry_date, days_to_expiry, underlying_price, atm_price, atm_iv):\n",
    "    \"\"\"Generate the non repeating part of an option record\"\"\"\n",
    "    base_record = {}\n",
    "    base_record['quote_date'] = quote_date\n",
    "    base_record['expiry_date'] = expiry_date\n",
    "    base_record['days_to_expiry'] = days_to_expiry\n",
    "    base_record['underlying_price'] = underlying_price\n",
    "    base_record['atm_price'] = round(atm_price, 2)\n",
    "    base_record['atm_iv'] = round(atm_iv, 3)\n",
    "    base_record['strike_prices'] = []\n",
    "    base_record['sampling_key'] = random.random()\n",
    "    return base_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_put_moneyness(atm_price, atm_iv, strike_price, days_to_expiry):\n",
    "    \"\"\"\n",
    "    calculate the probability that a put option will close in the money on expiry date\n",
    "    Note that the probability of a call option with the same strike price closing in the money\n",
    "    will be 1 - the probability of the put option closing in the money    \n",
    "    \"\"\"\n",
    "    iv_to_expiry = atm_iv * math.sqrt(days_to_expiry / 365)\n",
    "    zscore = math.log(strike_price /  atm_price) / iv_to_expiry\n",
    "    norm_cdf = scipy.stats.norm.cdf(zscore)\n",
    "    return norm_cdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strike_record(row):\n",
    "    \"\"\"Generate a strike price record\"\"\"\n",
    "    strike_record = {}\n",
    "    strike_record['strike_price'] = row['strike_price']\n",
    "       \n",
    "    #call attributes\n",
    "    strike_record['call_bid'] = row['call_bid']\n",
    "    strike_record['call_ask'] = row['call_ask']\n",
    "    strike_record['call_volume'] = row['call_volume']\n",
    "    strike_record['call_open_interest'] = row['call_open_interest']\n",
    "    strike_record['call_moneyness'] = round(1 - row['put_moneyness'], 3)\n",
    "    strike_record['call_iv'] = round(row['call_iv'],3)\n",
    "    \n",
    "     #put attributes\n",
    "    strike_record['put_bid'] = row['put_bid']\n",
    "    strike_record['put_ask'] = row['put_ask']\n",
    "    strike_record['put_volume'] = row['put_volume']\n",
    "    strike_record['put_open_interest'] = row['put_open_interest']\n",
    "    strike_record['put_moneyness'] = round(row['put_moneyness'], 3)\n",
    "    strike_record['put_iv'] = round(row['put_iv'], 3)\n",
    "        \n",
    "    return strike_record\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_expiry_date(df_expiry, interest_rate):\n",
    "    \"\"\"\n",
    "    read and process options for a given expiry date\n",
    "    \"\"\"\n",
    "    #transpose calls and puts into a straddle layout\n",
    "    df_straddle = merge_options(df_expiry)\n",
    "\n",
    "    #find nearest strike price\n",
    "    target_index = abs(df_straddle['strike_price'] - df_straddle['underlying_price']).idxmin()\n",
    "    df_strike = df_straddle.loc[target_index]\n",
    "\n",
    "    #get option values at target strike price\n",
    "    quote_date = df_strike['quote_date'].strftime('%Y-%m-%d')\n",
    "    expiry_date = df_strike['expiry_date'].strftime('%Y-%m-%d')\n",
    "    underlying_price = df_strike['underlying_price']\n",
    "    strike_price = df_strike['strike_price']\n",
    "    days_to_expiry = (df_strike['expiry_date'] -  df_strike['quote_date']).days \n",
    "    call_price = (df_strike['call_bid'] + df_strike['call_ask']) / 2\n",
    "    put_price = (df_strike['put_bid'] + df_strike['put_ask']) / 2\n",
    "\n",
    "    #find adjusted underlying price and Implied Volatility where call and put implied volatility are the same\n",
    "    atm_price, atm_iv = center_underlying_price(underlying_price, strike_price, interest_rate, \n",
    "        days_to_expiry, call_price, put_price)    \n",
    "  \n",
    "    #calculate put moneyness and exclude options that are more that 2 stard deviations in or out of the money\n",
    "    df_straddle['put_moneyness'] = df_straddle.apply(lambda x: calc_put_moneyness(atm_price, atm_iv, x['strike_price'], days_to_expiry), axis=1)\n",
    "    df_straddle = df_straddle[(df_straddle['put_moneyness'] > .05) & (df_straddle['put_moneyness'] < .95)].reset_index(drop=True)\n",
    "\n",
    "    #calculate call implied volatilities using atm_price as the current price\n",
    "    df_straddle['call_iv'] = df_straddle.apply(lambda x: calc_call_iv(atm_price, x['strike_price'], \\\n",
    "        interest_rate, days_to_expiry, (x['call_bid'] + x['call_ask']) / 2), axis=1)\n",
    "  \n",
    "    #calculate put implied volatilities using atm_price as the current price\n",
    "    df_straddle['put_iv'] = df_straddle.apply(lambda x: calc_put_iv(atm_price, x['strike_price'], \\\n",
    "        interest_rate, days_to_expiry, (x['put_bid'] + x['put_ask']) / 2), axis=1)\n",
    "  \n",
    "    #create base record\n",
    "    base_record = create_base_record(quote_date, expiry_date, days_to_expiry, underlying_price, atm_price, atm_iv)\n",
    "\n",
    "    #add strike price records\n",
    "    for index, row in df_straddle.iterrows():\n",
    "        strike_record =  create_strike_record(row)\n",
    "        base_record['strike_prices'].append(strike_record)\n",
    " \n",
    "    return base_record\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_bq(records, symbol):\n",
    "    \"\"\"Write records to bigquery dataset\"\"\"\n",
    "    client = bq.Client(project=PROJECT_ID)\n",
    "    table_id = '{}.{}.{}'.format(PROJECT_ID, DATASET_ID, symbol.upper())\n",
    "    table = client.get_table(table_id)\n",
    "    errors = client.insert_rows(table, records)\n",
    "    if errors == []:\n",
    "        print(\"Records have been inserted\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_quote_date(df_daily, quote_date, symbol):\n",
    "    \"\"\"\n",
    "    process options for a given symbol and quote date\n",
    "    - save transformed data to bigquery dataset    \"\"\"\n",
    "    #get fed funds rate that was effective on the supplied quote date\n",
    "    interest_rate = get_interest_rate(quote_date)\n",
    "    \n",
    "    #get list of expiry dates\n",
    "    expiry_dates = df_daily['expiry_date'].unique()\n",
    "       \n",
    "    #process each expiry date and store results in json line format\n",
    "    data = ''\n",
    "    for expiry_date in expiry_dates:\n",
    "        df_expiry = df_daily[df_daily['expiry_date'] == expiry_date].reset_index(drop=True)\n",
    "        base_record = process_expiry_date(df_expiry, interest_rate)\n",
    "        data += json.dumps(base_record) + '\\n'\n",
    "   \n",
    "    #save processed data to bigquery\n",
    "    save_to_bq(data, symbol)    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_of_week_dates(start_date, end_date):\n",
    "    \"return a list of end of week trading days between start_date and end_date\"\n",
    "    \"start and end dates must be passed in as date values (without time component)\"\n",
    "    eow_dates = []\n",
    "    date_offsets = [4, 3, 2, 1, 0, 6, 5]\n",
    "    offset = date_offsets[start_date.weekday()]\n",
    "    next_date = start_date + datetime.timedelta(days=offset)\n",
    "   \n",
    "    #load stock exchange holidays\n",
    "    nyse = mcal.get_calendar('NYSE')\n",
    "    market_holidays = nyse.holidays().holidays\n",
    "   \n",
    "    while next_date <= end_date:\n",
    "        #subtract 1 day from next_date if it is a market holiday\n",
    "        if next_date in market_holidays:\n",
    "            adj_date = next_date - datetime.timedelta(days=1)\n",
    "            eow_dates.append(adj_date)\n",
    "        else:\n",
    "            eow_dates.append(next_date)\n",
    "        next_date += datetime.timedelta(days=7)\n",
    "    return eow_dates\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 1, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = df_options['quote_date'].dt.date.min()\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path, symbol):\n",
    "    \"\"\"\n",
    "    capture options data on a weekly cadence\n",
    "    file path is path to options input file\n",
    "    example: gs://expiry-week-data/options/SPY_2020.csv\n",
    "    \"\"\"\n",
    "    #load file into a dataframe\n",
    "    input_columns = [0,1,5,6,7,8,10,11,12,13]\n",
    "\n",
    "    column_names = ['underlying_symbol', 'underlying_price', 'option_type', 'expiry_date', 'quote_date',\n",
    "        'strike_price', 'bid', 'ask', 'volume', 'open_interest']\n",
    "\n",
    "    df_options = pd.read_csv(file_path, usecols=input_columns, names=column_names, header=0, parse_dates=[3,4])\n",
    "    df_options = df_options[(df_options['underlying_symbol'] in STOCK_SYMBOLS) &\n",
    "       (df_options['expiry_date'] > df_options['quote_date'])]\n",
    "          \n",
    "    #get end of week quote dates\n",
    "    start_date = df_options['quote_date'].dt.date.min()\n",
    "    end_date = df_options['quote_date'].dt.date.max()\n",
    "    eow_dates = end_of_week_dates(start_date, end_date)\n",
    "    \n",
    "    #process each stock symbol\n",
    "    for symbol in STOCK_SYMBOLS:\n",
    "\n",
    "        #process end of week quote dates\n",
    "        for quote_date in eow_dates:\n",
    "            df_daily = df_options[df_options['quote_date'].dt.date == quote_date]\n",
    "            process_quote_date(df_daily, quote_date, symbol)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Exploration Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = 'gs://expiry-week-data/options/SPY_2019.csv'\n",
    "df_options = main(file_path, 'SPY')\n",
    "print('All Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-51a06d03190e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#process end of week quote dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_daily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quote_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0meow_dates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprocess_quote_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_daily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meow_dates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SPY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-3527b1c65336>\u001b[0m in \u001b[0;36mprocess_quote_date\u001b[0;34m(df_daily, quote_date, symbol)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#save processed data to bigquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msave_to_bq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-f46bca3fdec0>\u001b[0m in \u001b[0;36msave_to_bq\u001b[0;34m(records, symbol)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtable_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}.{}.{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Records have been inserted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36minsert_rows\u001b[0;34m(self, table, rows, selected_fields, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m             )\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m         \u001b[0mjson_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_record_field_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_rows_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2531\u001b[0m             )\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m         \u001b[0mjson_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_record_field_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_rows_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/_helpers.py\u001b[0m in \u001b[0;36m_record_field_to_json\u001b[0;34m(fields, row_value)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0msubvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misdict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# None values are unconditionally omitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "#get end of week quote dates\n",
    "start_date = df_options['quote_date'].dt.date.min()\n",
    "end_date = df_options['quote_date'].dt.date.max()\n",
    "eow_dates = end_of_week_dates(start_date, end_date)\n",
    "\n",
    "#process end of week quote dates\n",
    "df_daily = df_options[df_options['quote_date'].dt.date == eow_dates[0]]\n",
    "process_quote_date(df_daily, eow_dates[0], 'SPY')\n",
    "print('All Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create storage client\n",
    "storage_client = gcs.Client()\n",
    "# get bucket with name\n",
    "bucket = storage_client.get_bucket('expiry-week-data')\n",
    "# get bucket data as blob\n",
    "blob = bucket.get_blob('staging/SPY_20190104.jsonl')\n",
    "# convert to string\n",
    "json_data = blob.download_as_string()\n",
    "lines = json_data.split(b'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
